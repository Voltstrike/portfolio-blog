[
  {
    "title": "Introduction",
    "content": "Hello readers, My name is Mikail Crito Husada. most people call me Mikail, nice to meet all of you dear readers. i just created this portfolio blog to showcase my projects portfolio and create articles that talks about my projects or some of my idea. i hope you will enjoy and follow this journey with me. once again thanks for reading this articles and coming to my portfolio blog. lets have a nice journey together everyone. ",
    "id": 1757855700249,
    "date": "2025-09-14T13:15:00.249Z"
  },
  {
    "id": 1759395532596,
    "slug": "cnn-using-mnist-dataset",
    "title": "CNN using MNIST Dataset",
    "content": "sss",
    "date": "2025-10-02T08:58:52.596Z"
  },
  {
    "id": 1759395873018,
    "slug": "predicting-billboard-ranks-with-machine-learning-an-intro",
    "title": "Predicting Billboard Ranks with Machine Learning : An Intro",
    "content": "Before we get into machine learning, we need to set up the foundation: the Billboard Hot 100 dataset. This dataset, sourced from Kaggle, contains detailed weekly chart information going back decades.\n\n🔍 What’s in the Dataset?\n\nThe dataset includes key columns such as:\n\ndate → The Billboard chart week.\n\nrank → The current week’s Hot 100 position (our target variable).\n\nsong → Track title.\n\nartist → Performer(s).\n\nlast-week → Position in the previous week.\n\npeak-rank → The highest position the song has ever reached.\n\nweeks-on-board → How many weeks the song has stayed on the Hot 100.\n\nThese features make it possible to spot trends—like whether a song is rising, falling, or stable.\n\n🧹 Preprocessing Steps\n\nCleaning Missing Values\n\nSome entries don’t have complete rank history (especially when a song first enters the chart). These were handled carefully so the model doesn’t misinterpret them.\n\nColumn Standardization\n\nRenamed and reformatted columns for consistency (e.g., replacing hyphens with underscores).\n\nFeature Engineering\n\nFocused on predictive features like last_week, peak_rank, and weeks_on_board.\n\nConverted categorical text columns (like artist) into usable numeric form where necessary.\n\nNormalization\n\nScaled numeric values so that features like “weeks on board” and “rank” are comparable to each other.\n\n💡 Why This Step Matters\n\nA machine learning model can’t make sense of raw Billboard data without preparation. By cleaning and structuring the dataset, we give the model the chance to actually learn patterns—like why some songs shoot to #1 while others slowly fade.",
    "date": "2025-10-02T09:04:33.018Z"
  },
  {
    "id": 1759440010103,
    "slug": "predictiong-ranks-with-machine-learning-preparing-dataset",
    "title": "Predictiong Ranks with Machine Learning : Preparing Dataset ",
    "content": "Before any machine learning magic can happen, the most important step is understanding and cleaning the data. A model is only as good as the data it learns from—so this stage sets the foundation for everything else.\n\n🔍 The Dataset\n\nFor this project, I used a structured dataset (sourced from Kaggle)  that contains features related to individual performance. In this case Each row represents a person, and each column describes something about them—for example:\n\nExam or test scores\n\nParticipation/attendance metrics\n\nPerformance in certain activities\n\nFinal outcome (rank/position)\n\nThis rank column is what we want to predict.\n\n🧹 Preprocessing Steps\n\nRaw data almost always needs some work before it’s ready for machine learning. Here’s what I did:\n\nCleaning Missing Values\n\nSome rows had incomplete information. I either filled them with reasonable estimates (like averages) or removed them if too much data was missing.\n\nRenaming and Standardizing Columns\n\nTo avoid confusion later, I made sure column names were consistent and easy to read.\n\nFeature Selection\n\nNot every column in the dataset helps with prediction. I selected the most relevant features that likely influence rank.\n\nEncoding and Normalization\n\nIf there were any categorical variables (like “yes/no” fields), I converted them into numbers so the model could understand them.\n\nI also scaled numerical values so that features with large ranges didn’t overpower smaller ones.\n\n💡 Why This Matters\n\nPreprocessing might feel less exciting than model training, but it’s absolutely critical. If the data is messy or poorly prepared, even the best machine learning model will struggle. By making the dataset clean and structured, we give the model the best chance to learn meaningful patterns.",
    "date": "2025-10-02T21:20:10.103Z"
  }
]